{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize and manage datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a data analyst or scientist, you probably have one or more datasets kept in different folders on your laptop or PC. To better organize the datasets, you can write them to one SQLite database file and manage them from there.\n",
    "\n",
    "With all your datasets in a single database file, you can:\n",
    "\n",
    "* add up more dataset to the database at any time.\n",
    "* list and view all the datasets in the database at any time.\n",
    "* view the fields or columns of each dataset or table.\n",
    "* load any dataset directly from the database.\n",
    "* drop any dataset or table as you like.\n",
    "\n",
    "How to do that? Follow the codes in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SQLite database file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a SQLite database\n",
    "    # log in to your terminal, change to the folder where you want to keep the database file.\n",
    "    # type the following code and change xxxx to a name you want to give the database. Mine is called datarepo:\n",
    "\"\"\"\n",
    "sqlite3 xxxx.db \n",
    "\n",
    ".databases\n",
    "\n",
    "\"\"\"\n",
    "# press control D to exit the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the datasets into the SQLite file\n",
    "The following formats are currently supported:\n",
    "* csv\n",
    "* xls/xlsx\n",
    "* txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "import os\n",
    "import sys\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# Connect to the database\n",
    "conn = create_engine('sqlite:///datarepo.db')\n",
    "\n",
    "# Define full path to the directory containing all the datasets to be written \n",
    "datapath = '/Users/xxxx/xxxx/dataset'\n",
    "\n",
    "# a list to hold information\n",
    "datfile = []\n",
    "file_in_database = []\n",
    "new_datfile = []\n",
    "\n",
    "# store the existing txt and csv datasets in a list datfile\n",
    "if os.path.isdir(datapath):\n",
    "    for i in os.listdir(datapath):\n",
    "        ipath = os.path.join(datapath, i)\n",
    "        if os.path.isfile(ipath):\n",
    "            if os.path.splitext(ipath)[1] == '.txt' or os.path.splitext(\n",
    "                    ipath)[1] == '.csv' or os.path.splitext(\n",
    "                        ipath)[1] == '.xlsx' or os.path.splitext(\n",
    "                            ipath)[1] == '.xls':\n",
    "                datfile.append(ipath)\n",
    "\n",
    "# read the existing files in the database and store the information in a list file_in_database                \n",
    "sql = \"select tbl_name from sqlite_master where type='table'\"\n",
    "res = pd.read_sql(sql, conn)\n",
    "for i in [j for k in res.values.tolist() for j in k]:\n",
    "    file_in_database.append(os.path.join(datapath, i))\n",
    "\n",
    "# get the list of new datasets that have not been written to the database\n",
    "for file in datfile:\n",
    "    if file not in file_in_database:\n",
    "        new_datfile.append(file)\n",
    "\n",
    "# check whether list of new datasets is empty         \n",
    "if len(new_datfile) == 0:\n",
    "    print(\n",
    "        \"The datasets in the source folder have all already been written to the database.\"\n",
    "    )\n",
    "    sys.exit\n",
    "\n",
    "# otherwise, write the new datasets to the database\n",
    "else:\n",
    "    for file in new_datfile:\n",
    "\n",
    "        #write excel dataset\n",
    "        if file.split(\".\")[-1] == 'xlsx' or file.split(\".\")[-1] == 'xls':\n",
    "            tab_name = file.split(\"/\")[\n",
    "                -1]  # strip the path and get the file name only\n",
    "            start = dt.datetime.now()\n",
    "            df = pd.read_excel(file)\n",
    "            df.to_sql(tab_name, conn, if_exists='append')\n",
    "            print('{} seconds: writing of {} to the database is completed.'.\n",
    "                  format((dt.datetime.now() - start).seconds, tab_name))\n",
    "\n",
    "        #write csv or txt dataset\n",
    "        if file.split(\".\")[-1] == 'csv' or file.split(\".\")[-1] == 'txt':\n",
    "            tab_name = file.split(\"/\")[\n",
    "                -1]  # strip the path and get the file name only\n",
    "            start = dt.datetime.now()\n",
    "            chunksize = 1000  # you can increase the chunksize\n",
    "            counter = 0\n",
    "            index_start = 1\n",
    "\n",
    "            for df in pd.read_table(\n",
    "                    file, chunksize=chunksize, iterator=True,\n",
    "                    encoding='utf-8'):\n",
    "                df.index += index_start\n",
    "                counter += 1\n",
    "\n",
    "                print('{} seconds: completed {} rows'.format((\n",
    "                    dt.datetime.now() - start).seconds, counter * chunksize))\n",
    "\n",
    "                df.to_sql(tab_name, conn, if_exists='append')\n",
    "                index_start = df.index[-1] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List and view all the datasets in the database file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the database\n",
    "conn = create_engine('sqlite:///datarepo.db')\n",
    "\n",
    "\n",
    "# Get the list of current datasets in the database\n",
    "def list_dataset():\n",
    "    try:\n",
    "        sql = \"select tbl_name from sqlite_master where type='table'\"\n",
    "        return pd.read_sql(sql, conn)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "\n",
    "#list_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View a dataset fields or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the database\n",
    "conn = create_engine('sqlite:///datarepo.db')\n",
    "\n",
    "\n",
    "# View a dataset columns or fields\n",
    "def view_dataset_cols(table_name):\n",
    "    try:\n",
    "        h = \"'\" + table_name + \"'\"\n",
    "        sql = (\n",
    "            \"select sql from sqlite_master where type ='table' and tbl_name = %s\"\n",
    "            % h)\n",
    "        x = pd.read_sql(sql, conn)\n",
    "        j = str(x.values.tolist())\n",
    "        k = j[:len(j) - 6]\n",
    "        return k.split(\"\\\\n\\\\t\")[1:]\n",
    "\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "\n",
    "#view_dataset_cols('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a dataset into a dataframe directly from the database file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the database\n",
    "conn = create_engine('sqlite:///datarepo.db')\n",
    "\n",
    "\n",
    "# Load a dataset into a dataframe\n",
    "def load_dataset(table_name):\n",
    "    try:\n",
    "        tabname = \"'\" + table_name + \"'\"\n",
    "        sql = \" SELECT * FROM %s\" % tabname\n",
    "        return pd.read_sql(sql, conn)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "# You can amend the SQL code to select only the needed fields from a dataset. \n",
    "        \n",
    "#j = load_dataset('housing.csv')\n",
    "#j.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop any dataset from the database file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the database\n",
    "conn = create_engine('sqlite:///datarepo.db')\n",
    "\n",
    "\n",
    "# Drop a dataset\n",
    "def drop_dataset(table_name):\n",
    "    try:\n",
    "        tabname = \"'\" + table_name + \"'\"\n",
    "        sql = \"DROP TABLE %s\" % tabname\n",
    "        print('The dataset: ' + tabname + ' has been dropped from the database.')\n",
    "        pd.read_sql(sql, conn)\n",
    "\n",
    "    except Exception as err:\n",
    "        pass\n",
    "\n",
    "\n",
    "#drop_dataset('test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
